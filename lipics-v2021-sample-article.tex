
\documentclass[a4paper,UKenglish,cleveref, autoref, thm-restate, numberwithinsect]{lipics-v2021}
\nolinenumbers

%This is a template for producing LIPIcs articles. 
%See lipics-v2021-authors-guidelines.pdf for further information.
%for A4 paper format use option "a4paper", for US-letter use option "letterpaper"
%for british hyphenation rules use option "UKenglish", for american hyphenation rules use option "USenglish"
%for section-numbered lemmas etc., use "numberwithinsect"
%for enabling cleveref support, use "cleveref"
%for enabling autoref support, use "autoref"
%for anonymousing the authors (e.g. for double-blind review), add "anonymous"
%for enabling thm-restate support, use "thm-restate"
%for enabling a two-column layout for the author/affilation part (only applicable for > 6 authors), use "authorcolumns"
%for producing a PDF according the PDF/A standard, add "pdfa"
\usepackage{natbib}
\usepackage{booktabs}
\usepackage{framed}
\usepackage{tabularx}
\usepackage{bm}
\usepackage{mdframed}
\usepackage{tikz}
\usetikzlibrary{arrows.meta, positioning}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode} 
\input{paper_commands.tex}

\pdfoutput=1 %uncomment to ensure pdflatex processing (mandatatory e.g. to submit to arXiv)
%\hideLIPIcs  %uncomment to remove references to LIPIcs series (logo, DOI, ...), e.g. when preparing a pre-final version to be uploaded to arXiv or another public repository

%\graphicspath{{./graphics/}}%helpful if your graphic files are in another directory

% \bibliographystyle{plainurl}% the mandatory bibstyle
\bibliographystyle{abbrvnat}

\title{Interactive Proofs For Distribution Testing With Conditional Oracles} %Please add   DONE:

\author{Ari Biswas}{University Of Warwick, United Kingdom  \and \url{https://randomwalks.xyz}}{tcs@randomwalks.xyz}{https://orcid.org/0000-0001-6412-844X}{Supported by The Chancellors International Scholarship}
%mandatory, please use full name; only 1 author per \author macro; first two parameters are mandatory, other parameters can be empty. Please provide at least the name of the affiliation and the country. The full address is optional. Use additional curly braces to indicate the correct name splitting when the last name consists of multiple name parts.   DONE:

\author{Mark Bun}{Boston University, USA \and \url{https://cs-people.bu.edu/mbun/}}{mbun@bu.edu}{[orcid]}{}

\author{Cl\'ement L. Canonne}{University of Sydney, Australia \and \url{https://ccanonne.github.io}}{clement.canonne@sydney.edu.au}{https://orcid.org/0000-0001-7153-5211}{Supported by an ARC DECRA (DE230101329).}

\author{Satchit Sivakumar}{Boston University, USA \and \url{https://sites.google.com/view/satchit/home?pli=1}}{satchit.sivakumar@gmail.com}{[orcid]}{Supported by the Apple fellowship in AI/ML}

\authorrunning{A. Biswas, M. Bun, C. Cannone, S. Sivakumar} %mandatory. First: Use abbreviated first/middle names. Second (only in severe cases): Use first author plus 'et al.'   DONE:

\Copyright{Ari Biswas, Mark Bun, Cl\'ement Canonne and  Satchit Sivakumar} %mandatory, please use full first names. LIPIcs license is "CC-BY";  http://creativecommons.org/licenses/by/3.0/   DONE:

% \ccsdesc[100]{\textcolor{red}{Replace ccsdesc macro with valid one}} %mandatory: Please choose ACM 2012 classifications from https://dl.acm.org/ccs/ccs_flat.cfm    DONE:
\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10003752.10003753.10003759</concept_id>
       <concept_desc>Theory of computation~Interactive computation</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Theory of computation~Interactive computation}
\keywords{Distribution Testing, Interactive Proofs} %mandatory; please add comma-separated list of keywords   DONE:

\category{} %optional, e.g. invited paper

% DONE: add full version
\relatedversion{Full Version} %optional, e.g. full version hosted on arXiv, HAL, or other respository/website
% \relatedversiondetails[linktext={opt. text shown instead of the URL}, cite=]{Full Version}{https:://randomwalks.xyz/papers/itcs_2026_ipdp_extended_fullversion.pdf} %linktext and cite are optional
\relatedversiondetails
[linktext={\url{https://randomwalks.xyz/papers/itcs_2026_ipdp_fullversion.pdf}} ]
  {URL}
  {https://randomwalks.xyz/papers/itcs_2026_ipdp_fullversion.pdf}
%\supplement{}%optional, e.g. related research data, source code, ... hosted on a repository like zenodo, figshare, GitHub, ...
%\supplementdetails[linktext={opt. text shown instead of the URL}, cite=DBLP:books/mk/GrayR93, subcategory={Description, Subcategory}, swhid={Software Heritage Identifier}]{General Classification (e.g. Software, Dataset, Model, ...)}{URL to related version} %linktext, cite, and subcategory are optional

%\funding{(Optional) general funding statement \dots}%optional, to capture a funding statement, which applies to all authors. Please enter author specific funding statements as fifth argument of the \author macro.

%optional
\acknowledgements{This work was started while AB and CC were visiting the Simons Institute for the Theory of Computing as part of the Sublinear Algorithms program.}

%\nolinenumbers %uncomment to disable line numbering



%Editor-only macros:: begin (do not touch as author)%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\EventEditors{Shubhangi Saraf}
\EventNoEds{1}
\EventLongTitle{17th Innovations in Theoretical Computer Science Conference (ITCS 2026)}
\EventShortTitle{ITCS 2026}
\EventAcronym{ITCS}
\EventYear{2026}
\EventDate{January 27--30, 2026}
\EventLocation{Bocconi University, Milan, Italy}
\EventLogo{}
\SeriesVolume{362}
\ArticleNo{8}
\begin{document}

\maketitle

%mandatory: add short abstract of the document   DONE:
\begin{abstract}
We revisit the framework of interactive proofs for distribution testing, first introduced by Chiesa and Gur (ITCS 2018), which has recently experienced a surge in interest, accompanied by notable progress (e.g., Herman and Rothblum, STOC 2022, FOCS 2023; Herman, RANDOM~2024). 
In this model, a data-poor verifier  determines whether a probability distribution has a property of interest by interacting with an all-powerful, data-rich but untrusted prover bent on convincing them that it has the property. While prior work gave sample-, time-, and communication-efficient protocols for testing and estimating a range of distribution properties, they all suffer from an inherent issue: for most interesting properties of distributions over a domain of size $N$, the verifier must draw at least $\Omega(\sqrt{N})$ samples of its own. While sublinear in $N$, this is still prohibitive for large domains encountered in practice.

In this work, we circumvent this limitation by augmenting the verifier with the ability to perform an exponentially smaller number of more powerful (but reasonable) \emph{pairwise conditional} queries, effectively enabling them to perform ``local comparison checks'' of the prover's claims.
We systematically investigate the landscape of interactive proofs in this new setting, giving poly-logarithmic query and sample protocols for (tolerantly) testing all \emph{label-invariant} properties, thus demonstrating exponential savings without compromising on communication, for this large and fundamental class of testing tasks.
\end{abstract}

\section{Introduction}\label{sec:intro}

 Distribution testing, as introduced by~\citet{BatuFRSW00}, is a mature subfield of property testing~\citep{GoldreichGR98, rubinfeldRobust} aimed at investigating statistical properties of an unknown distribution given sample access to it. 
 Given a property (a set of distributions) and a proximity parameter $\Proximity \in (0, 0.1]$, distribution testing algorithms output $\Accept$ if the distribution is in the property (or close to it), or $\Reject$ if the distribution is $\Proximity$-far from the property, both with high probability. Closeness and farness are quantified with respect to a prespecified notion of distance, typically total variation distance.
The primary motivation behind distribution testing is to design testing algorithms for deciding properties with sample complexity sub-linear in the domain size $\DomainSize$ (which is demonstrably more efficient than learning the distribution, which requires  drawing $\BigTheta{\DomainSize}$ samples).
Accordingly, over the last two decades, researchers have extensively studied the sample complexity of numerous distribution properties, such as simple uniformity testing~\citep{goldreich2011testing} (testing whether a distribution is uniform over its entire domain), support size decision problem~\citep{RaskhodnikovaRSS09,ValiantV11,YihongP19,PintoH25} (testing whether a distribution's support is within some pre-specified range), 
and many more: see, e.g.,~\cite[Chapter~11]{Goldreich17} and~\cite{Rubinfeld12,Canonne20,CanonneTopicsDT2022} for a more thorough introduction to distribution testing. 
Unfortunately, although distribution testing is often more efficient than learning the distribution, it is still prohibitively expensive for practical use. 
For example, it is known that generalized uniformity testing (testing whether a distribution is uniform over its support) over a domain of size $\DomainSize$ requires $\BigOmega{\DomainSize^{2/3}}$ samples~\citep{BatuC17,DiakonikolasKS18}, which can be impractical for large domain sizes. 
Even simple uniformity testing requires $\Omega(\sqrt{N})$ samples~\citep{Paninski08}, and its \emph{tolerant} testing version (which asks to distinguish distributions \emph{close} to uniform from those which are far) needs $\BigOmega{\DomainSize/\log \DomainSize}$ samples~\citep{valiant2017estimating}.

In the face of these limitations, a nascent line of work \citep{chiesa2018proofs, herman2022verifying, herman2023doubley, herman2024public} has asked a related question: \textit{with testing being hard by itself, what is the complexity of \emph{verifying} the properties of a distribution given sample access to it?}
Here, in addition to drawing samples from the distribution, the tester is allowed to interactively communicate with an omniscient but \emph{untrusted} prover that knows the distribution in its entirety. 
The idea here is to leverage the provers extra knowledge about the distribution, with the hope that checking the provers' claims is easier than naively testing the property.
While this model of verifiable computation has only recently been explored in the context of distribution testing, it has been an active area of research in other areas of theoretical computer science for over 40 years (see for e.g. \citep{goldwasserZK1985, silvioSoundProofs, rvw14, goldwasserMuggles15, berman2018, arun2024jolt}).
It models settings where a centralized organization (for example, a company turning billions of dollars of profit) has the ability to collect large amounts of data and learn distributions to high precision, while end-users may not have the same ability. 
At the same time, the company might have incentives to lie, and so verifying whether the company is being truthful is important in this setting.
% This line of work shows that for broad classes of properties, verifying properties is indeed more sample-efficient than testing them. 
The work of \citet{chiesa2018proofs} shows that the verification of \emph{any} distribution property over domain $\Domain$ can be reduced to identity testing\footnote{Identity testing refers to the task of testing distinguishing between distributions that are  exactly equal to a pre-specified reference distribution from distributions $\Proximity$-far from in total variation distance.}, with communication \emph{superlinear} in the domain size. 
Follow up work \citep{herman2022verifying, herman2023doubley} recovers this result for the broad class of \emph{label-invariant properties}, while only requiring communication \emph{sub-linear} in the domain size.
More specifically, the work of \citet{herman2022verifying, herman2023doubley} show that for label-invariant properties, verification requires only $\BigO{\sqrt{\DomainSize}}$ samples and $\BigOTilde{\sqrt{\DomainSize}}$ communication, even though, as mentioned earlier, testing some properties in this class could require $\Theta(N/\log N)$ samples. 
Here, a property is \emph{label-invariant} (also known as \emph{symmetric}) if the names of the elements themselves are not significant to the decision outcome. 
% More formally, a property $\Property$ of distributions over domain $\mathcal{X}$ is label-invariant if, whenever distribution $\Dist$ satisfies $\Property$, then so does every distribution $\Dist_\pi$ obtained by re-labelling domain elements in $\mathcal{X}$ with a permutation $\pi\colon \mathcal{X} \rightarrow \mathcal{X}$. 
Testing if a distribution is uniform over its support (also known as generalized uniformity testing) is an example of a label-invariant property. 

Unfortunately, while a significant improvement over unaided testing, requiring $\BigO{\sqrt{\DomainSize}}$ samples from the verifier can still be prohibitive when considering massive domains. 
Further, there is a matching sample complexity lower bound -- verification of even basic label-invariant properties such as checking if a distribution is uniform over its entire domain requires $\Omega(\sqrt{N})$ samples\footnote{This lower bound applies to any property that is a singleton set.}. 
To summarise: For most properties, with access to \emph{only} samples from a distribution, it is impossible for any tester to do better than drawing $\BigOmega{\sqrt{\DomainSize}}$ samples, with or without the help of a prover.
%More formally, given a distribution $D$ over a domain $[N]$ with a property $P$, it is label-invariant, if for any permutation $\pi: [N] \to [N]$, the distribution $D_{\pi}$ where $D_{\pi}(x) = D(\pi(x))$ has the property $P$. 
%Label-invariant properties include tolerant uniformity testing, entropy testing, support size testing etc. 
To bypass these limitations and develop more practical algorithms, in this work we study  verifiers that can make a very small number of calls to a more powerful \emph{conditional sampling} oracle. These oracles were introduced in the context of distribution testing \citep{chakraborty2013power, CRS:14}; allowing the tester to condition that samples from the oracle come from a subset $S$ of the domain, of their choosing. 
The oracle responds with a sample with probability re-normalised over $S$.
If no element in $S$ is supported, the oracle responds with $\Fail$.
Since specifying an arbitrary set may considered be unrealistic for practical purposes, a commonly studied restriction is the pairwise conditional sampling model ($\PCond$), where the specified sets are restricted to be of size exactly $2$ or the entire domain (thus, just a regular sample from the distribution). 
These oracles can be thought of as allowing for local comparisons between the probabilities of two points. 
While access to a $\PCond$ oracle can be significantly helpful for problems like simple uniformity testing, it is unclear from prior work whether it results in more efficient testing for the general class of label-invariant properties. 
Verification with access to a $\PCond$ oracle (or any type of conditional sampling oracle) has also, to the best of our knowledge, not been explored. 
In our quest to find practical algorithms that work for large domains, we thus ask the following question.




\begin{framed}
        {\it Can label-invariant properties be verified in a (query, sample and communication)-efficient  way when the tester has access to a $\PCond$ oracle? 
%        How does the query complexity of verification compare with that of testing label-invariant properties with access to a $\PCond$ oracle?
        }
\end{framed}


\subsection{Our Results}

Our main result is an \emph{exponential} query complexity separation between testing and verification for testing label-invariant properties with access to a $\PCond$ oracle. A detailed accounting of our results and comparison to existing work can be found in Table~\ref{tab:comparison}. A description follows.

 \begin{table}[h!]
\centering
\begin{tabularx}{\linewidth}{l *{4}{>{\centering\arraybackslash}X} >{\centering\arraybackslash}X >{\centering\arraybackslash}X}
\toprule
 & Query Complexity Without Prover & Query Complexity With Prover & Communication & Rounds \\
\midrule
  $\Samp$  & $\BigOmegaTilde{\frac{\DomainSize}{\log \DomainSize}}$ \cite{valiant2017estimating} 
         & $\BigOTilde{\sqrt{\DomainSize}}$ \citep{herman2022verifying,herman2023doubley}
         & $\BigOTilde{\sqrt{\DomainSize}}$ \citep{herman2022verifying,herman2023doubley}
         & 2 \citep{herman2022verifying,herman2023doubley} \\\\
$\PCond$ & $\bm{\BigOmega{\DomainSize^{1/3}}}$
         & $\bm{\text{poly}(\log \DomainSize,\frac{1}{\Proximity})}$
         & $\bm{\BigOTilde{\sqrt{\DomainSize}}}$ 
         & $\bm{\text{poly}(\log \DomainSize, \frac{1}{\Proximity})}$   \\
         &&\multicolumn{3}{c}{}\\
\bottomrule
\end{tabularx}
\caption{Results on testing and verifying label-invariant properties under different types of access to the distribution. We state the best known lower bounds for label invariant properties.
For $\Samp$ the lower bound is for entropy estimation, whereas for $\PCond$ it is the support size decision problem described in Section 3 of the full version.
The upper bounds apply for all label-invariant properties.
Our results are highlighted in bold.
}  
\label{tab:comparison}
\end{table}

One might have initially hoped that the power of a $\PCond$ oracle allows us to test label-invariant properties efficiently, even without the help of a prover. Indeed, with access to the full power of the $\Cond$ model (where arbitrary subsets $S$ can be queried and a sample conditional on $S$ is obtained), \cite{chakraborty2013power} show that this class of properties over a domain of size $N$ can be tested with $O(\poly \log N)$ queries to the $\Cond$ oracle. 
Our first result dashes this hope~--~we show a lower bound on the number of $\PCond$ queries required to test label-invariant properties with constant proximity parameter $\Proximity$, demonstrating that the $\PCond$ oracle is not much better in the worst case than the sampling oracle for this class of properties. 
Specifically, we show that a simple variant of the support size distinguishing problem for distributions over a domain of size $\DomainSize$ requires $\Omega(\DomainSize^{1/3})$ queries to a $\PCond$ oracle (the exact same as with access to only a sampling oracle).
Thus, unaided, there exist (label-invariant) properties for which the $\PCond$ oracle is not much better than just sample access. 
% Specifically, the property is the set of distributions with support size $\sqrt{N}$.

\begin{theorem}[Informal Version]\label{thm:informallb}

  There exists a label-invariant property $\Property$ such that every tester with access to a $\PCond$ oracle for $\Property$ with proximity parameter  $\Proximity \leq 1/2$ and failure probability  $0.01$ must make $\BigOmega{\DomainSize^{1/3}}$ queries.
\end{theorem}

The above lower bound motivates the investigation of verification with access to a $\PCond$ oracle. 
% Specifically, we consider the setting described in \cite{chiesa2018proofs}, where the prover is all-powerful, i.e., it has access to the true distribution. 
As mentioned earlier, \cite[Proposition 3.4]{chiesa2018proofs} showed that with super-linear communication complexity, there exists a reduction from verification to identity testing.
Instantiating this reduction with an identity tester using $\PCond$ oracles \citep[Theorem 1.5]{narayanan2020distribution}, we get that there exists an interactive proof system for every property with super-linear communication complexity that makes only $O(\sqrt{\log N}/\Proximity^2)$ queries to the $\PCond$ oracle. 
However, super-linear communication is also prohibitive for practical algorithms; the proof systems by \citet{herman2022verifying, herman2023doubley} require the prover to only communicate $\tilde{O}(\sqrt{\DomainSize})$ domain elements, but still achieve the sample complexity of identity testing (for the class of label-invariant properties).
Could we also hope to achieve such communication while maintaining similar query complexity as that of identity testing? 
The main result of this paper is an affirmative answer to this question.
Specifically, we give an interactive proof system for tolerantly verifying \emph{any} label-invariant property that has communication complexity $\tilde{O}(\sqrt{N})$ and query complexity $\poly(\log N)$ (suppressing the dependence on the proximity parameter). 


\begin{theorem}[Informal Label-Invariant Tolerant Verification Theorem ]\label{thm:introlabelinv}
  Fix a label-invariant property $\Property$ over a domain $[N]$ and proximity parameters $\Proximity_c, \Proximity_f \in (0, 1/2]$. 
  There exists a polylogarithmic (in $\DomainSize$) round interactive protocol $\Protocol$ between an honest verifier $\TesterFunc$, and an omniscient untrusted prover $\Prover{\Dist}$, where the verifier has $\PCond$ access to $\Dist$, such that at the end of the interaction the verifier satisfies the following conditions:
	\begin{enumerate}
    \item{\textbf{Completeness:} If the prover follows the protocol as prescribed, and $\TV{D}{\Property} \leq \Proximity_c$, then
		      \[ \Prob{\outputs{\ProofSystem{\Dist}{\Proximity_c, \DomainSize}} = \Accept } \geq 2/3 \]
		      }
        \item{\textbf{Soundness:} If $\TV{D}{\Property} \geq \Proximity_f$, then for any prover $\tilde{\Prover{\Dist}}$ 

		      \[ \Prob{\outputs{\ChProofSystem{\Dist}{\Proximity_c, \DomainSize}} = \Reject } \geq 2/3 \]

		      }
	\end{enumerate}

	%The probability in the above statements is taken over the randomness of the oracle answers, and the verifiers private randomness.
The complexity of the verifier is as follows:
  \begin{enumerate}
    \item \textbf{Query Complexity + Sample Complexity}: $O\left(\poly(\log N, 1/(\Proximity_f - \Proximity_c) )\right)$
    \item \textbf{Communication Complexity:} $\tilde{O} \left( \sqrt{N} \poly(1/(\Proximity_f - \Proximity_c)) \right)$
  \end{enumerate}
\end{theorem}


In the process of proving this result, we give protocols for more basic primitives that may be of independent interest. Most significantly, we give an interactive proof system that is able to calculate the approximate probability mass of any point\footnote{Provided it does not have prohibitively small probability mass in its neighbourhood.} in the domain using communication complexity $\tilde{O}(\sqrt{N})$ and query complexity $O(\poly(\log N, 1/\Proximity))$. 
As we will explain in the techniques section to follow, this is a key technical workhorse in our protocol for verifying label-invariant properties.

\begin{theorem}[Informal Version]\label{informal:approxsingle}
    Fix a domain $\Domain$. For every $\Proximity > 0$ and $\delta \in (0,1/2)$, there exists a $O(\ \poly(\log N, \log 1/ \delta, \frac{1}{\tau}))$-round  interactive proof system such that the verifier $\TesterFunc$ with access to a $\PCond$ oracle satisfies the following.
	\begin{enumerate}

		\item \textbf{Completeness:} For every distribution $\Dist$, if the prover $\Prover{\Dist}$ is honest, then
		      \[ \Prob{ \TesterFunc \text{ outputs } (\yStar, \ClaimedDist{\yStar}) \text{ s.t } \frac{\ClaimedDist{\yStar}}{\TrueDist{\yStar}} \in \left[\frac{1}{(1+\Proximity)} , 1 + \Proximity \right] } \ge 1 - \delta \]


		\item{ \textbf{Soundness:} For any cheating prover $\ChProver{\Dist}$, then

		      \[ \Prob{ \TesterFunc \text{ outputs } \Reject \lor \TesterFunc \text{ outputs } (\yStar, \ClaimedDist{\yStar}) \text{ s.t } \frac{\ClaimedDist{\yStar}}{\TrueDist{\yStar}} \in [1/(1 + \Proximity)^2, (1 + \Proximity)^2]} \ge 1-\delta \]

		      }

	\end{enumerate}
The complexity of the verifier is as follows:
  \begin{enumerate}
    \item \textbf{Query Complexity + Sample Complexity}: $O\left(\poly(\log N, 1/(\Proximity) )\right)$
    \item \textbf{Communication Complexity:} $\tilde{O} \left( \sqrt{N} \poly(1/(\Proximity)) \right)$
  \end{enumerate}
%  The sample complexity is given by $O(\poly(\log N, 1/\Proximity))$, the query complexity is given by $O(\poly(\log N, 1/\Proximity))$

\end{theorem}

\subsection{Technical Overview}

In this section, we give an overview of our protocol for verifying label-invariant properties.

\paragraph*{Unlabelled Bucket Histogram:} There is now a long line of work on the testing and verification of label-invariant properties \citep{BatuFRSW00, valiantthesis, chakraborty2013power, herman2022verifying, herman2023doubley}, and a key object used in this work is the unlabelled \emph{approximate} $\Proximity$-bucket histogram of a distribution. 
Bucketing corresponds to partitioning the interval $[0,1]$ into smaller multiplicative probability intervals. 
The $\Proximity$-bucket histogram divides the interval $[0,1]$ into $\BigOTilde{\log \DomainSize /\Proximity}$ buckets where the $\ell$\textsuperscript{th} bucket is a set of domain elements with individual probability mass in the range $(\Proximity(1+\Proximity)^{\ell} / N, \Proximity(1+\Proximity)^{\ell+1} / N]$. 
The \emph{approximate} unlabelled bucket histogram of a distribution then corresponds to a list of $\tilde{O}(\log N / \Proximity)$ fractions, where the $\ell$\textsuperscript{th} element of the list is the fraction of domain points whose probability lies in the range specified by the $\ell$\textsuperscript{th} bucket.
It is well known (see \citep{valiantthesis}) that the \emph{approximate} unlabelled $\Proximity$-bucket histogram of a distribution is a sufficient statistic to (tolerantly) test any label-invariant property with proximity parameter(s) $\BigO{\Proximity}$. 
Thus, similar to prior work \citep{herman2022verifying, herman2023doubley, herman2024public}, our protocol also focuses on efficiently verifying an unlabelled $\Proximity$-bucket histogram given to us by the prover.

\paragraph*{Using Pairwise Comparisons to Learn Bucket Histogram:} Note that the unlabelled bucket histogram is a distribution over the buckets of the $\Proximity$-bucket histogram and is hence a distribution over a domain of size $\tilde{O}(\log \frac{N}{\Proximity})$. 
Hence, by standard results in distribution learning, $\tilde{O}(\log N/\Proximity^2)$ samples from this bucket distribution would be sufficient to learn it. 
However, sampling from this bucket distribution is non-trivial since a sample from the original distribution $\Dist$ does not come with information about histogram bucket index. 

While sampling from the bucket distribution might be hard with $\Samp$ access to the distribution, one might be more optimistic about the possibility of sampling from the $\Proximity$-approximate histogram with $\PCond$ queries. 
In particular, one approach that we might take is the following: the verifier draws a dataset of size $\tilde{O}(\log N/\Proximity^2)$ (enough to learn the histogram), and sends these samples to the prover, who responds with the bucket index of each sample.
From how a $\Proximity$-histogram is defined, if $x$ and $y$ belong to buckets $i$ and $j$ respectively, then this implies that the ratio of the probability masses of $x$ and $y$ under $\Dist$ is guaranteed to be in the interval $\left[\frac{1}{(1+\Proximity)^{|j-i|}}, (1 + \Proximity)^{|j-i|}\right]$.
As $\PCond$ access allows us to conditionally sample from a set restricted to two domain elements, it allows us to approximately learn the ratio of their probability masses up to a multiplicative constant.
Equipped with this power, for each pair $x \neq y$ from the set of drawn samples, the verifier uses the $\PCond$ oracle to check if the learned ratios align with the provers claims.
If the prover were to lie significantly, then for at least one pair of samples, the claimed ratio would significantly different from the learned ratio.
Unfortunately, this simplistic strategy comes with two pitfalls. 
Firstly, assuming the above strategy was sound, naively comparing elements with arbitrary bucket indices could require $\BigOmega{\DomainSize}$ $\PCond$ queries if the elements being compared had significantly different probability masses.
This would be as bad as learning the distribution itself. 
Secondly, and more importantly, the above strategy is \emph{not} sound. 
It does not catch a prover that ``slides'' all samples into different buckets \emph{in the same way}, i.e., it lies about \emph{every} bucket index by the same offset.
As an example, consider two distributions: $\Dist_1$ is the uniform distribution over $N^{1/4}$ domain elements and $\Dist_2$ is the uniform distribution over $\sqrt{N}$ domain elements. 
The bucket histograms of both involve a unit mass on a single (but different) bucket. 
However, pairwise comparisons between samples taken from either distribution will always reveal a ratio that is approximately $1$, since the probabilities of all elements in the support of both distributions are identical. 
Hence, given distribution $\Dist_1$, the prover can output the bucket histogram of distribution $\Dist_2$, and it is impossible for a verifier to catch it purely by using the test described above. %(without crossing over the $\poly(\DomainSize)$ sample complexity we want to avoid). 

A remedy to these obstacles lies in the following  observation.
If we had a good estimate of the probability mass of \emph{a single point} $y$ in the domain, then we could resolve the soundness issue discussed above.
We simply use the $\PCond$ oracle to learn the ratio of probabilities between each of our samples and $y$.
Using this ratio, and knowledge of the approximate mass of $y$, we can compute estimates of the probabilities of all samples.
%Of course we need to account for the noise of the oracle, but at least in expectation this would get us what we want.
This would squash the sliding attack described above. 
%If the tester knew the mass of $y$, distinguishing between the cases discussed above is trivial.
To deal with the first issue (that of the probability mass of $y$ being very far from that of a sample), we would need to do more than learn just one value of $y$.
Instead, we could learn the mass of a point $y_j$, for every bucket $j$ that has large enough mass.
This way, for any sample $x$ in the tester's set of samples (which are likely to come from buckets with sufficiently large mass), we can find some $y_j$ that is in a near-by bucket with high probability.

\paragraph*{Verifying the probability of points:} Given that we simply need to identify the probability of a few points in the domain, one might expect that this could be done even without access to a prover~---~this would give a query-efficient tester for label-invariant properties. 
However, this ends up being a surprisingly challenging task. Indeed, our lower bound in Theorem~\ref{thm:informallb} shows that this is impossible (if we wanted to bypass the $\poly(\DomainSize)$ lower bound). 
This indicates a power of an untrusted prover; it is able to certify the probability of a few points in the distribution support. 
Indeed, the proof system with super-linear communication \cite{chiesa2018proofs} achieves something stronger- it certifies the entire distribution. 
Since we only need to certify the mass of at most $\BigO{\log \DomainSize}$ points, we ask if this be done in a more communication efficient way?

\paragraph*{Support Size Verification:} Inspired by the ``sliding'' cheating prover from earlier, we consider the orthogonal but related problem of verifying the support size of a flat distribution.\footnote{A distribution is \emph{flat} if it is uniform over its support.} 
We will subsequently show that a protocol for this problem can be combined with the ability of a $\PCond$ oracle to learn neighbourhoods around points, enabling us to solve the probability approximation problem for ``relevant'' domain elements.

Given a support size claim represented by four numbers $A',A,B,B'$, corresponding to the claim that $A' < A \leq \Support{\Dist} \leq B < B'$, our hope is to accept if the claimed support size range is accurate, and reject if the true support is larger than $B'$ or smaller than $A'$. 
Given different values of $A$ and $B$, we develop a number of tests to verify with \emph{sub-linear} communication, the support size assuming the distribution is uniform over its support\footnote{We relax this condition in the main protocol, but assuming uniformity makes the description more intuitive.}. 
We summarize the ideas below.

If the claimed support size upper bound $B$ is small (that is, $\BigO{\sqrt{\DomainSize}}$), we could ask the prover to send us the claimed support of the distribution. 
If the prover lies, and the true support is actually much larger, then taking a few samples from the distribution would give us a domain element outside the claimed support, thus catching the lie of the prover. 
If the true support is much smaller than $A$, then taking a number of uniform samples from the claimed support sent by the prover would result in a sample outside the support of the distribution, which could be easily detected with a few $\PCond$ queries. 
This gives us a protocol with a constant number of queries, and communication complexity roughly $O(B)$. 

On the other hand, if the claimed support size lower bound $A$ is large (that is, $\SmallOmega{\sqrt{\DomainSize}}$), then asking the prover to send the support is not communication-efficient. Our approach instead involves using uniform samples from the domain. %, and relying on the fact that it the prover does not know which samples are drawn from the true distribution, and which are uniformly drawn. 
The first test is to catch provers that lie that the support is much larger than it really is. 
It involves drawing $O(N/A)$ uniform samples $S_1$ from the domain, and sending them to the prover. 
We ask the prover to send back a sample in this subset that is in the support of the distribution. 
If the true support is much smaller than $A$, there are (with high probability) no samples in the support of the distribution in $S_1$, and we can ensure the prover does not cheat by checking whether any element it sends back is in the support using a constant number of $\PCond$ queries. 
The second test catches provers that lie that the support is much smaller than it really is. 
It involves drawing $O(N/B')$ samples $z_1,\dots,z_m$ uniformly from the domain and permuting them with one sample $x$ taken from the distribution. 
We ask the prover to identify the index of $x$ in the permuted set.
If the true support is smaller than $B$, then w.h.p, we expect that none of $z_1,\dots,z_s$ are in the support of the distribution and hence, the honest prover can identify $x$ exactly. 
On the other hand, if the support is larger than $B'$, we expect that at least one of $z_1,\dots,z_s$ is in the support of the distribution, and the prover is unable to tell what the sample inserted by the prover was (since it could be $x$ or $z_i$).  
This gives us a protocol with a constant number of queries, and communication complexity roughly $O(N/A)$. 
Balancing parameters in these tests to optimize the communication complexity, we get an overall protocol for support size verification with communication complexity roughly $\sqrt{N}$.

We emphasize that the above outline is a simplification of the truth, and sweeps important details under the rug. 
Recall that our main goal is to certify the histogram of a distribution. 
In an attempt to do so, we will use the support size protocol above repeatedly as a sub-routine. 
This requires bounding the soundness and completeness errors in a meaningful way.
As described above, these protocols do not have low enough soundness and completeness error to be used as sub-routines. 
Additionally, the above description assumes that distributions are exactly flat. 
In practice this will not be the case, and we need to be able to handle distributions where the probability ratio between any two elements in the support is upper bounded by some constant $\alpha$ (nearly flat).
We show how to analyse the protocols above to facilitate amplification of soundness and completeness errors, and make the protocol work for the more general class of $\alpha$-flat distributions. 

\paragraph*{Estimating Probability of a Point using Support Size Verification:} Finally, we explain how we can use the support size protocols to estimate the probability of a point. 
Prior work \citep{canonne2015testing} using the $\PCond$ oracle has shown that it can be used to estimate the mass within a multiplicative $(1+\Proximity)$-neighbourhood of any point\footnote{As long as the point does not have prohibitively small probability mass under the distribution.}.
We ask the prover to send us a point $\yStar$ \footnote{Recall that in the final protocol, we will ask the prover to send us points from every bucket with sufficiently large mass. For simplicity, we consider a single point in this description.} with sufficiently large mass in its neighbourhood (by an averaging argument, at least one histogram bucket needs to have $\Proximity/\log N$ mass, ensuring that such a point exists, and tell us the bucket the $\yStar$ belongs to.
We then use the $\PCond$ oracle to estimate the mass within the multiplicative neighbourhood of $\yStar$. 
The learned mass of the neighborhood divided by the prover's claimed probability mass\footnote{The bucket index gives a lower and upper bound on the true probability mass of $\yStar$. This is sufficient to catch a cheating prover.} of $\yStar$ gives us bounds on the number of elements in $\yStar$'s neighbourhood.
Additionally, by definition the neighbourhood of $\yStar$ will be nearly flat.  
Hence, we have reduced the problem to a claim about the support size of a nearly-uniform distribution over a subset of the domain. 
Observe that we can sample from the distribution restricted to this bucket using $\PCond$ queries---since there is sufficient mass in the neighbourhood of the point, $O(\poly \log N)$ samples from the distribution will contain at least one sample from the bucket, and we can use $\PCond$ queries between the samples and $\yStar$ to find out which sample it is. 
If the prover was telling the truth (or rather did not lie egregiously), then the support size claim holds and the verifier will accept, thereby giving us a point and its approximate probability mass\footnote{The claimed mass of $\yStar$ is derived from the bucket sent by the prover.}. 
If the prover significantly lied, then the support size claim will be false and the prover will be caught. 
We note that the final analysis needs to handle some additional subtleties, since the $\PCond$ oracle is itself only approximate and does not provide perfect comparisons (which can affect the sampling), and additionally the bucket boundaries and the neighbourhood of the provided point do not overlap precisely. 
Once we have estimated the probability of important points, we can use the ratio learning techniques discussed earlier to certify the prover's claim about the bucket histogram of the distribution. 
We refer the reader to the full version for precise technical details. 


\subsection{Other Related Work:}

\paragraph*{Interactive Proofs for Distribution Testing:} As mentioned earlier, interactive proofs for verifying distribution properties were first introduced in the work of \cite{chiesa2018proofs}. Follow-up work \citep{herman2022verifying, herman2023doubley} studied interactive proofs for verifying \emph{label-invariant} properties, focusing on sublinear communication, and doubly efficient protocols (i.e. computationally-efficient and sample-efficient generation of a proof). \cite{herman2024public} studied \emph{public-coin }interactive proofs for testing label-invariant properties, where the verifier has no private randomness. \cite{HermanR24} gives communication-efficient and sample-efficient interactive proofs for more general distribution properties that can be decided by uniform polynomial-size circuits with bounded depth. \cite{HermanR25} introduces \textit{computationally sound} interactive proofs and shows communication-, time-, and sample-efficient protocols for any distribution property that can be decided in polynomial time given explicit access to the full list of distributiom probabilities. All of the above works assume that the verifier only has sample access to the distribution, and the verifier sample complexity in all of them is $\Omega(\sqrt{N})$ (where $N$ is the size of the domain). 

\paragraph*{Interactive Proofs for Learning:} A related but orthogonal line of work \citep{GoldwasserRSY21, MutrejaS23, GurJKRSS24, CaroHINS24, CarosHINS25} focuses on interactive proofs for verifying learning problems-  for a specific hypothesis class $H$, given access to an untrusted prover, the goal is for a verifier to output an accurate hypothesis from $H$ for an underlying unknown distribution $D$ if the resource-rich prover is honest, and to reject if the prover lies egregiously. Different types of resource asymmetry between the prover and the verifier are explored in these papers -- including differing number of samples, different computational complexities, different types of access to the underlying function (sample vs query), and differing access to computational resources (classical vs quantum computation and communication).


\paragraph*{Distribution testing under conditional oracles:} Our work focuses on interactive proofs for \textit{verifying} distribution properties under conditional sampling models. There is a long line of work on \emph{testing} with access to conditional samples. \citet{chakraborty2013power, CRS:14} introduced the conditional sampling ($\Cond$) model and its more restricted variants ($\PCond, \ICond$). They gave algorithms for uniformity testing, tolerant uniformity testing, identity testing etc. in these conditional sampling models with query and sample complexity significantly better than the $\Samp$ model. Follow-up work shows improved bounds for identity testing (and its tolerant version), tolerant uniformity testing, and new algorithms for other tasks such as equivalence testing and support size problem in the $\Cond$ model \citep{falahatgar2015faster, narayanan2020distribution, ChakrabortyKM23, ChakrabortyCK24}. 
There is also a line of work studying the power of non-adaptive queries in the conditional sampling model \citep{AcharyaCK15, KamathT19}. The $\PCond$ model was studied in detail by \cite{narayanan2020distribution} who gave optimal bounds for identity testing and tolerant uniformity testing in this model, improving on results from \cite{canonne2015testing}. Testing under other types of conditional sampling has also been studied in the literature including subcube conditioning, where the distribution is supported on the hypercube, and the tester is allowed to ask for conditional samples from subcubes \citep{BhattacharyyaC18, CanonneCKLW21, ChenJLW21, KumarMM23, ChakrabartyCR0W25}, and coordinate conditional sampling \citep{BlancaCSV25} (a version of subcube conditioning where all but one coordinate is fixed to a specific configuration and a sample is obtained from the remaining coordinate). Testing under other types of access to the distribution such as Probability Mass Function queries or Cumulative Distribution Function queries has also been studied in the literature \citep{BatuDKR02, RubinfeldS05, GuhaMV09,  CanonneR14,OnakS18}.



%%
%% Bibliography
%%

%% Please use bibtex, 

\bibliography{lipics-v2021-sample-article}

\end{document}
